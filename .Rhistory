progressive_percent = progressive / total * 100,
conservatism_percent = conservative / total * 100) %>%
mutate(date = ymd(doc_id)) %>%
mutate(speaker = substr(doc_id, 12, 25))
time_df %>%
filter(date > as.Date("2018-01-01")) %>%
ggplot(aes(date, populism_percent, color = speaker)) +
geom_point()
speeches_time
time_dfm
speeches_time <- tidy_speeches %>%
mutate(date = floor_date(date, "month"))
time_corpus <- corpus(speeches_time, text_field = "text")
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3)
time_dfm <- dfm(time_toks, groups = c("date", "speaker"))
time_words <- dfm_select(time_dfm, pattern = content_dict, selection = "keep")
time_categories <- dfm_lookup(time_dfm, dictionary = content_dict)
time_df <- convert(time_categories, to = "data.frame") %>%
group_by(doc_id) %>%
mutate(total = populism + environment + immigration + progressive + conservative) %>%
mutate(populism_percent = populism / total * 100,
environment_percent = environment / total * 100,
immigration_percent = immigration / total * 100,
progressive_percent = progressive / total * 100,
conservatism_percent = conservative / total * 100) %>%
mutate(date = ymd(doc_id)) %>%
mutate(speaker = substr(doc_id, 12, 25))
time_df %>%
filter(date > as.Date("2018-01-01")) %>%
ggplot(aes(date, populism_percent, color = speaker)) +
geom_point()
time_dfm
speeches_time <- tidy_speeches %>%
mutate(date = floor_date(date, "week"))
time_corpus <- corpus(speeches_time, text_field = "text")
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3)
time_dfm <- dfm(time_toks, groups = c("date", "speaker"))
time_words <- dfm_select(time_dfm, pattern = content_dict, selection = "keep")
time_categories <- dfm_lookup(time_dfm, dictionary = content_dict)
time_df <- convert(time_categories, to = "data.frame") %>%
group_by(doc_id) %>%
mutate(total = populism + environment + immigration + progressive + conservative) %>%
mutate(populism_percent = populism / total * 100,
environment_percent = environment / total * 100,
immigration_percent = immigration / total * 100,
progressive_percent = progressive / total * 100,
conservatism_percent = conservative / total * 100) %>%
mutate(date = ymd(doc_id)) %>%
mutate(speaker = substr(doc_id, 12, 25))
time_df %>%
filter(date > as.Date("2018-01-01")) %>%
ggplot(aes(date, populism_percent, color = speaker)) +
geom_point()
time_dfm
time_df
View(time_df)
time_dfm
speeches_time <- tidy_speeches %>%
filter(speaker == "Donald Trump") %>%
filter(date > as.Date("2018-01-01")) %>%
mutate(date = floor_date(date, "week"))
speeches_time
time_corpus <- corpus(speeches_time, text_field = "text")
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3)
time_dfm <- dfm(time_toks, groups = c("date", "speaker"))
time_dfm
speeches_time <- tidy_speeches %>%
filter(speaker == "Donald Trump") %>%
filter(date > as.Date("2018-01-01")) %>%
mutate(date = floor_date(date, "month"))
time_corpus <- corpus(speeches_time, text_field = "text")
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3)
time_dfm <- dfm(time_toks, groups = c("date"))
time_dfm
textplot_wordcloud(time_dfm, comparison = T)
?floor_date
speeches_time <- tidy_speeches %>%
filter(speaker == "Donald Trump") %>%
filter(date > as.Date("2018-01-01")) %>%
mutate(date = floor_date(date, "bimonth"))
speeches_time
time_corpus <- corpus(speeches_time, text_field = "text")
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3)
time_dfm <- dfm(time_toks, groups = c("date"))
textplot_wordcloud(time_dfm, comparison = T)
tstat_freq <- textstat_frequency(time_dfm)
head(tstat_freq, 100)
time_dfm %>%
textplot_scale1d(groups = speaker,
margin = "documents")
?textplot_xray
textplot_xray(time_dfm)
textplot_wordcloud(time_dfm, comparison = T, min_count = 50)
textplot_wordcloud(time_dfm, comparison = T, min_count = 20)
?floor_date
speeches_time <- tidy_speeches %>%
filter(speaker == "Donald Trump") %>%
filter(date > as.Date("2018-01-01")) %>%
mutate(date = floor_date(date, "year"))
time_corpus <- corpus(speeches_time, text_field = "text")
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3)
time_dfm <- dfm(time_toks, groups = c("date"))
textplot_wordcloud(time_dfm, comparison = T, min_count = 20)
speeches_time <- tidy_speeches %>%
filter(speaker == "Donald Trump") %>%
mutate(date = floor_date(date, "year"))
time_corpus <- corpus(speeches_time, text_field = "text")
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3)
time_dfm <- dfm(time_toks, groups = c("date"))
textplot_wordcloud(time_dfm, comparison = T, min_count = 20)
time_words <- dfm_select(time_dfm, pattern = content_dict, selection = "keep")
textplot_wordcloud(time_words, comparison = T, min_count = 20)
recent_keyness <- textstat_keyness(time_dfm, target = "2020-01-01")
recent_relative <- textplot_keyness(recent_keyness)
recent_relative
recent_keyness <- textstat_keyness(time_words, target = "2020-01-01")
recent_relative <- textplot_keyness(recent_keyness)
recent_relative
old_keyness <- textstat_keyness(time_words, target = "2016-01-01")
old_relative <- textplot_keyness(old_keyness)
old_relative
recent_relative
recent_keyness <- textstat_keyness(time_df, target = "2020-01-01")
recent_keyness <- textstat_keyness(time_dfm, target = "2020-01-01")
recent_relative <- textplot_keyness(recent_keyness)
recent_relative
?textplot_keyness
recent_relative <- textplot_keyness(recent_keyness, n = 15L)
recent_relative
recent_keyness <- textstat_keyness(time_dfm, target = "2020-01-01")
recent_relative <- textplot_keyness(recent_keyness, n = 15L)
recent_relative
trump_relative
recent_keyness <- textstat_keyness(time_dfm, target = "2020-01-01")
recent_relative <- textplot_keyness(recent_keyness, n = 15L)
ggsave(path = "images", filename = "trump_recent_relative.png", height = 6, width = 10)
speeches_time <- tidy_speeches %>%
filter(speaker == "Donald Trump") %>%
filter(date > as.Date("2018-01-01")) %>%
mutate(date = floor_date(date, "bimonth"))
time_corpus <- corpus(speeches_time, text_field = "text")
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3)
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3) %>%
tokens_ngrams(n = 2)
time_dfm <- dfm(time_toks, groups = c("date"))
textplot_wordcloud(time_dfm, comparison = T, min_count = 20)
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3) %>%
tokens_ngrams(n = 3)
time_dfm <- dfm(time_toks, groups = c("date"))
textplot_wordcloud(time_dfm, comparison = T, min_count = 20)
textplot_wordcloud(time_dfm, comparison = T, min_count = 5)
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3) %>%
tokens_ngrams(n = 4)
time_dfm <- dfm(time_toks, groups = c("date"))
textplot_wordcloud(time_dfm, comparison = T, min_count = 5)
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3) %>%
tokens_ngrams(n = 1)
time_dfm <- dfm(time_toks, groups = c("date"))
textplot_wordcloud(time_dfm, comparison = T, min_count = 5)
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3) %>%
tokens_ngrams(n = 2)
time_dfm <- dfm(time_toks, groups = c("date"))
textplot_wordcloud(time_dfm, comparison = T, min_count = 5)
textplot_wordcloud(time_dfm, comparison = T, min_count = 5)
time_dfm
textplot_wordcloud(time_dfm, comparison = T, min_count = 15)
?textplot_wordcloud
trump_months_wordcloud <- textplot_wordcloud(time_dfm, comparison = T, min_count = 15)
trump_months_wordcloud
textplot_wordcloud(time_dfm, comparison = T, min_count = 15)
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3) %>%
tokens_ngrams(n = 2)
time_dfm <- dfm(time_toks, groups = c("date"))
textplot_wordcloud(time_dfm, comparison = T, min_count = 15)
textplot_wordcloud(time_dfm, comparison = T, min_count = 15)
speeches_time <- tidy_speeches %>%
filter(speaker == "Joe Biden") %>%
filter(date > as.Date("2018-01-01")) %>%
mutate(date = floor_date(date, "bimonth"))
time_corpus <- corpus(speeches_time, text_field = "text")
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3) %>%
tokens_ngrams(n = 2)
time_dfm <- dfm(time_toks, groups = c("date"))
speech_corpus <- corpus(tidy_speeches, text_field = "text")
speech_toks <- tokens(speech_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3)
speech_dfm <- dfm(speech_toks, groups = "speaker")
all_words_cloud <- textplot_wordcloud(speech_dfm, color = c("red", "orange",
"yellowgreen", "green",
"blue", "purple", "violet"),
comparison = T)
tidy_speeches$date <- mdy(tidy_speeches$date)
tidy_speeches$date <- mdy(tidy_speeches$date)
speeches_time <- tidy_speeches %>%
filter(speaker == "Donald Trump") %>%
mutate(date = floor_date(date, "year"))
time_corpus <- corpus(speeches_time, text_field = "text")
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_wordstem() %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3)
time_dfm <- dfm(time_toks, groups = c("date"))
ggsave(path = "images", filename = "trump_recent_relative.png", height = 6, width = 10)
speeches_time <- tidy_speeches %>%
filter(speaker == "Donald Trump") %>%
filter(date > as.Date("2018-01-01")) %>%
mutate(date = floor_date(date, "bimonth"))
time_corpus <- corpus(speeches_time, text_field = "text")
tidy_speeches <- speeches %>%
clean_names() %>%
filter(speaker == "Donald Trump" | speaker == "Hillary Clinton" |
speaker == "Bernie Sanders" | speaker == "Mitt Romney" |
speaker == "Barack Obama" | speaker == "John McCain" |
speaker == "Joe Biden")
tidy_speeches$date <- mdy(tidy_speeches$date)
speeches_time <- tidy_speeches %>%
filter(speaker == "Donald Trump") %>%
filter(date > as.Date("2018-01-01")) %>%
mutate(date = floor_date(date, "bimonth"))
time_corpus <- corpus(speeches_time, text_field = "text")
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3) %>%
tokens_ngrams(n = 2)
time_dfm <- dfm(time_toks, groups = c("date"))
trump_months_wordcloud <- textplot_wordcloud(time_dfm, comparison = T, min_count = 15)
trump_months_wordcloud
trump_months_wordcloud <- textplot_wordcloud(time_dfm, comparison = T, min_count = 15)
speeches_time <- tidy_speeches %>%
filter(speaker == "Joe Biden") %>%
filter(date > as.Date("2018-01-01")) %>%
mutate(date = floor_date(date, "bimonth"))
time_corpus <- corpus(speeches_time, text_field = "text")
time_toks <- tokens(time_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern= c("applause", "inaudible","cheers", "laughing",
"[applause]", "[inaudible]", "[cheers]",
"[laughing]", "(applause)", "(inaudible)","(cheers)",
"(laughing)", "joe","biden","donald","trump",
"president","kamala","harris", "john", "mccain", "romney",
"mitt", "governor", "senator", "bernie", "sanders", "barack",
"obama", "hillary", "clinton")) %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar=3) %>%
tokens_ngrams(n = 2)
time_dfm <- dfm(time_toks, groups = c("date"))
biden_months_wordcloud <- textplot_wordcloud(time_dfm, comparison = T, min_count = 15)
